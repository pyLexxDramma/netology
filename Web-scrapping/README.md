# Домашнее задание к лекции 6. «Web-scrapping»

**Описание:**

Это решение домашнего задания по веб-скрейпингу, реализованное на Python. Цель - извлечение информации о статьях с сайта Habr (https://habr.com/ru/articles/) на основе заданных ключевых слов. Задание разделено на основную и дополнительную части.

**Состав репозитория:**

*   `main_task.py`: Скрипт, выполняющий основное задание (поиск по preview текстам).
*   `additional_task.py`: Скрипт, выполняющий дополнительное задание (поиск по полному тексту статей).
*   `README.md`: Этот файл с описанием и инструкциями.

**Описание скриптов:**

*   **`main_task.py`:**

    1.  **Импортирует необходимые библиотеки:** `requests` для выполнения HTTP-запросов и `BeautifulSoup` для парсинга HTML.
    2.  **Определяет список ключевых слов:** `KEYWORDS` - список слов, по которым будет вестись поиск.
    3.  **Определяет функцию `find_articles(keywords)`:**
        *   Выполняет GET-запрос к странице со статьями на Habr.
        *   Использует `BeautifulSoup` для парсинга HTML-кода страницы.
        *   Находит все элементы `<article>` с классом `tm-articles-list__item`, представляющие отдельные статьи.
        *   Для каждой статьи:
            *   Извлекает дату публикации.
            *   Извлекает ссылку и заголовок статьи (предпринимает несколько попыток, т.к. структура Habr может отличаться для разных статей).
            *   Извлекает preview текст статьи (также с несколькими попытками, т.к. структура может отличаться).
            *   Выполняет поиск по preview тексту (приводит текст и ключевые слова к нижнему регистру для регистронезависимого поиска).
            *   Если найдено хотя бы одно ключевое слово, выводит информацию о статье в формате `<дата> – <заголовок> – <ссылка>`.
    4.  **Вызывает функцию `find_articles(KEYWORDS)`** для запуска скрипта с заданными ключевыми словами.

*   **`additional_task.py`:**

    1.  **Импортирует необходимые библиотеки:** `requests` и `BeautifulSoup`.
    2.  **Определяет список ключевых слов:** `KEYWORDS`.
    3.  **Определяет функцию `find_articles(keywords)`:**
        *   Выполняет GET-запрос к странице со статьями на Habr.
        *   Парсит HTML-код страницы.
        *   Находит все элементы `<article>`, представляющие статьи.
        *   Для каждой статьи:
            *   Извлекает дату публикации.
            *   Извлекает ссылку и заголовок статьи (с несколькими попытками).
            *   **Пытается получить полный текст статьи:**
                *   Выполняет GET-запрос к URL статьи.
                *   Парсит HTML-код страницы статьи.
                *   Извлекает текст статьи из элемента `div` с классом `tm-article-body`.
                *   **Обрабатывает возможные исключения (`requests.exceptions.RequestException`):** Если не удается получить полный текст статьи, пропускает статью (переходит к следующей).
            *   Выполняет поиск по полному тексту статьи (приводит текст и ключевые слова к нижнему регистру).
            *   Если найдено хотя бы одно ключевое слово, выводит информацию о статье в формате `<дата> – <заголовок> – <ссылка>`.
    4.  **Вызывает функцию `find_articles(KEYWORDS)`** для запуска скрипта с поиском по полному тексту.

**Важные моменты:**

*   Скрипты предназначены для работы с *текущей* структурой сайта Habr. Любые изменения в HTML-разметке сайта могут привести к поломке скриптов.
*   Для корректной работы скриптов требуется установить библиотеки `requests` и `BeautifulSoup4`. Рекомендуется использовать виртуальное окружение.
*   Код включает несколько попыток извлечения данных (заголовка, ссылки, preview текста), чтобы адаптироваться к различным структурам HTML, используемым на Habr.
*   В `additional_task.py` реализована обработка исключений при попытке получения полного текста статьи, чтобы скрипт продолжал работу даже если некоторые статьи недоступны.
*   В `additional_task.py` поиск выполняется *только* по полному тексту статьи.  Если не удается получить полный текст, статья пропускается.